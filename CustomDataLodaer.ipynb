{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules and Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "from torchvision.transforms.transforms import Normalize, ToTensor\n",
    "#imoprt labels.py\n",
    "from labels import Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root=\"dataset\", transform=None):\n",
    "        self.imagespath  = glob.glob('dataset/images/*.png') #get the image's directory, I'm familiar with glob\n",
    "        self.labelspath = glob.glob('dataset/labels/*.png')  #get the label's directory, I'm familiar with glob\n",
    "        self.root = root\n",
    "        \n",
    "        # try to print the path\n",
    "        print(\"Img Path: \", self.imagespath)\n",
    "        print(\"Label Path: \", self.labelspath)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self) -> int:        \n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        \n",
    "        #load image Dataset\n",
    "        img_data = self.imagespath[index]\n",
    "        image = Image.open(img_data)\n",
    "        \n",
    "        #load label Dataset\n",
    "        label_data = self.labelspath[index]\n",
    "        label = Image.open(label_data)\n",
    "        \n",
    "        #dictionary between image and label\n",
    "        sample_data = {\"image\":image, \"label\":label}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample_data = self.transform(sample_data)\n",
    "        return sample_data\n",
    "            \n",
    "    \n",
    "    def shows(self, image, label):\n",
    "        # Complete the implementation.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Horizontal Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorizontalFlip():\n",
    "    def __init__(self)-> None:\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, sample) -> dict:\n",
    "        image = sample[\"image\"]\n",
    "        label = sample[\"label\"]\n",
    "        transformedImage = transforms.RandomHorizontalFlip(p=1)(image) #do a random horizontal flip (probability 1, means all image will be flipped)\n",
    "        transformedLabel = transforms.RandomHorizontalFlip(p=1)(label) #do a random horizontal flip (probability 1, means all label will be flipped)\n",
    "        \n",
    "        return {\"image\":transformedImage, \"label\":transformedLabel}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Random Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop():\n",
    "    def __init__(self) -> None:\n",
    "            self.output_size = (512, 512)\n",
    "    \n",
    "    def __call__(self,sample) -> dict:\n",
    "        image = sample[\"image\"]\n",
    "        label = sample[\"label\"]\n",
    "\n",
    "        w, h = image.size               #get image size\n",
    "        new_h, new_w = self.output_size # determine new image size\n",
    "        \n",
    "        left = np.random.randint(0, w - new_w)  #create horizontal random location for cropping\n",
    "        top = np.random.randint(0, h - new_h)   #create vertical random location for cropping\n",
    "        print(\"image height :\",h,\"image weight :\",w)\n",
    "        print(\"height crop location :\",top,\"weight crop location :\",left)\n",
    "        \n",
    "        imagecropped = transforms.functional.crop(image, top,left,new_h,new_w) #crop image using the defined parameter before\n",
    "        labelcropped = transforms.functional.crop(label, top,left,new_h,new_w) #crop label using the same defined parameter before\n",
    "\n",
    "        return {\"image\": imagecropped, \"label\": labelcropped} #return the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imageNormalized():\n",
    "    def __init__(self) -> None:\n",
    "        self.mean = (0.485, 0.456, 0.406)\n",
    "        self.std = (0.229, 0.224, 0.225)\n",
    "        \n",
    "    def __call__(self,sample) -> dict:\n",
    "        image = sample[\"image\"]\n",
    "        label = sample[\"label\"]\n",
    "        trans = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            Normalize(self.mean, self.std)\n",
    "        ])\n",
    "        imageNormalized = trans(image)\n",
    "        labelTensored = transforms.ToTensor()(label)\n",
    "        \n",
    "        return {\"image\":imageNormalized, \"label\":labelTensored}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class imageDenormalize():    \n",
    "    def __init__(self) -> None:\n",
    "        self.mean = (-0.485/0.229, -0.456/0.224, -0.406/0.255)\n",
    "        self.std = (1/0.229, 1/0.224, 1/0.255)\n",
    "\n",
    "    def __call__(self, sample) -> dict:\n",
    "        image = sample[\"image\"]\n",
    "        label = sample[\"label\"]\n",
    "        trans = Normalize(self.mean, self.std)\n",
    "        imagedenorm = trans(image)\n",
    "        return {\"image\":imagedenorm, \"label\":label}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calling The Function Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Img Path:  ['dataset/images/78_iff_12.png', 'dataset/images/udu112_st55a.png', 'dataset/images/xz_77i.png', 'dataset/images/uff_987_stw.png', 'dataset/images/a_4564.png']\n",
      "Label Path:  ['dataset/labels/78_iff_12.png', 'dataset/labels/udu112_st55a.png', 'dataset/labels/xz_77i.png', 'dataset/labels/uff_987_stw.png', 'dataset/labels/a_4564.png']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a217c8127a0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load = CustomDataset(transform = imageDenormalize())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# plt.imshow(transforms.ToPILImage()(trial[\"image\"]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-0cd9f336798e>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0msample_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msample_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "alltransformation = transforms.Compose([imageNormalized(),imageDenormalize])\n",
    "load = CustomDataset(transform = alltransformation)\n",
    "\n",
    "# load = CustomDataset(transform = imageDenormalize())\n",
    "\n",
    "trial = load[1]\n",
    "\n",
    "# plt.imshow(transforms.ToPILImage()(trial[\"image\"]))\n",
    "# plt.figure()\n",
    "# plt.imshow(transforms.ToPILImage()(trial[\"label\"]))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
